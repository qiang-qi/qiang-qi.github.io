<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="jemdoc.css" type="text/css" />
  <title>齐强 (Qiang Qi)</title>
</head>
<body>
  <div id="layout-content">
  <div id="toptitle">
  <h1>齐强 (Qiang Qi)</h1>
  </div>
  <table class="imgtable"; style="margin-bottom: 3px;"><tr><td style="padding-right: 3px; vertical-align: top;">
    <a ><img src="qq.jpg" alt="alt text" width="154px" /></a>&nbsp;</td> 
    <td align="left"><p style="margin-left: 0;"></p><p>特聘副教授,&nbsp博士研究生<br />
     <a href="https://sjkx.qust.edu.cn/">数据科学学院</a><br>
    <a href="https://www.qust.edu.cn/">青岛科技大学</a><br>
    崂山, 青岛 266100, 中国 <br />
    邮箱: qiangq@qust.edu.cn <br /> 
   <!-- <a href="https://github.com/qiang-qi">[GitHub]!--> </p> 
    </td></tr></table>
  <h2>简介</h2>
  <p>青岛科技大学数据科学学院特聘副教授、硕士生导师。
    IEEE Transactions on Neural Networks and Learning Systems (TNNLS)、IEEE Transactions on Intelligent Transportation System (TITS)、IEEE Transactions on Circuits and Systems for Video Technology&nbsp(TCSVT)、IEEE Transactions on Geoscience and Remote Sensing&nbsp(TGRS)&nbsp等国际期刊审稿人。以第一作者身份在国际权威期刊 International Journal of Computer Vision (IJCV)、IEEE Transactions on Image Processing (TIP)、AAAI Conference on Artificial Intelligence (AAAI)、IEEE Transactions on Multimedia (TMM)、IEEE Transactions on Intelligent Transportation Systems (TITS)、
    IEEE Transactions on Circuits and Systems for Video Technology&nbsp(TCSVT)&nbsp上发表了多篇具有代表性的研究成果。<br>
  主要研究方向：<b>计算机视觉</b>、<b>人工智能</b>、<b>虚拟现实</b>、<b>目标检测和识别</b>。</p>
    <h2>其他情况简介</h2> 
    <p><b>招生情况：2025年拟招收3-5名硕士研究生。欢迎对我的研究方向感兴趣的同学与我联系（请直接邮件联系）。</b><br /><b>写给学生的话：</b>目前课题组涉及理论问题研究（纵向项目）和一些实际工程应用（横向项目），十分欢迎学习态度认真、动手能力好、团队意识强的同学加入课题组。我希望我的学生和我一起努力做出一流水平的研究，并写出高质量的学术论文（我希望我的学生研究生阶段大部分精力放在科研上面，只是为了混学历、混日子、热衷各种其他非学术活动的学生可能不适合我们课题组），
      也特别鼓励我的学生（我也会尽我最大努力帮助我的学生）在毕业后读硕士或博士、到高校/公司/研究院从事 技术和研发工作。<br /><b>算力资源：</b>目前课题组和学院拥有 Nvidia A100、Nvidia A10、 Nvidia RTX 3090 等GPU，同时从 AutoDL 购买在线算力作为缓冲算力资源池。 </p>
  <h2>教育背景</h2>
  <table class="imgtable"><tr><td>
    <a href="https://www.xmu.edu.cn/"></a>&nbsp;</td>
    <td align="left"><h3>博士 <a href="https://www.qust.edu.cn/">厦门大学，计算机科学与技术系</a> (2019.9 ~ 2023.12)</h3>
    </td></tr></table>
  <table class="imgtable"><tr><td>
      <a href="http://www.hdxy.edu.cn/"></a>&nbsp;</td>
      <td align="left"><h3>硕士 <a href="https://www.ouc.edu.cn/">中国海洋大学，计算机科学与技术系</a> (2015.9 ~ 2018.6)</h3>
      <ul>
      </li>
      </ul>
      </td></tr></table>
  <h2>学术论文</h2>
  <ul>
  <li><p>[1]<b>Q. Qi</b>, Qiu Z, Yan Y, Y. Lu, and H. Wang. IMC-Det: Intra–Inter Modality Contrastive Learning for Video Object Detection. International Journal of Computer Vision (IJCV), 2024, 133: 890-909. (国际顶级期刊、CCF A 类期刊、JCR Q1/中科院一区Top期刊，Impact Factor: 11.6)<br /> </p>
  </li>
  <li>[2]<b>Q. Qi</b>, T. Hou, Y. Lu, Y. Yan, and H. Wang. DGRNet: A Dual-Level Graph Relation Network for Video Object Detection. IEEE Transactions on Image Processing (TIP), 2023, 32: 4128-4141. (国际顶级期刊，CCF A 类期刊，JCR Q1 /中科院一区 Top 期刊，Impact Factor: 10.8)</li>
  <li>[3]<b>Q. Qi</b>, H. Wang, Y. Yan, and X. Li. DGC-Net: Dynamic Graph Contrastive Network for Video Object Detection. IEEE Transactions on Image Processing (TIP), 2025. (国际顶级期刊，CCF A 类期刊，JCR Q1 /中科院一区 Top 期刊，Impact Factor: 10.8)</li>
  <li>[4]<b>Q. Qi</b>, and X. Wang. TGBFormer: Transformer-GraphFormer Blender Network for Video Object Detection, The 39th AAAI Conference on Artificial Intelligence (AAAI), 2025. (国际顶级会议，CCF A 类会议)</li>
  <li>[5]<b>Q. Qi</b>, Y. Yan, and H. Wang. Class-Aware Dual-Supervised Aggregation Network for Video Object Detection. IEEE Transactions on Multimedia (TMM), 2024, 26: 2109-2123. (国际权威期刊，JCR Q1/中科院一区Top期刊，Impact Factor: 8.4)</li>
  <li>[6]<b>Q. Qi</b>, T. Hou, Y. Yan, Y. Lu, and H. Wang. TCNet: A Novel Triple-Cooperative Network for Video Object Detection. IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023, 33(8): 3649-3662. (国际权威期刊，JCR Q1/中科院一区Top期刊， Impact Factor: 8.3)</li>
  <li>[7]<b>Q. Qi</b>, X. Wang, T. Hou, Y. Yan, and H. Wang. FastVOD-Net: A Real-Time and High- Accuracy Video Object Detector. IEEE Transactions on Intelligent Transportation Systems (TITS), 2022, 23(11): 20926-20942. (国际权威期刊，JCR Q1/中科院一区Top期刊，Impact Factor: 7.9)</li>
  <li>[8]<b>Q. Qi</b>, M. Jian, Y. Yin, J. Dong, W. Zhang, and H. Yu. Saliency Detection Using Texture and Local Cues. CCF Chinese Conference on Computer Vision (CCCV), 2017: 689-699.</li>
  <li>[9]<b>Q. Qi</b>, M. Jian, Y. Yin, J. Dong, W. Zhang, and H. Yu. Saliency Detection via Combining Global Shape and Local Cue Estimation. International Conference on Intelligent Science and Big Data Engineering (IScIDE), 2017: 325-334. </li>
  <li> [10]	M. Jian, <b>Q. Qi</b>, H. Yu, J. Dong, C. Cui, X. Nie, H. Zhang, Y. Yin, and K. Lam. The Extended Marine Underwater Environment Database and Baseline Evaluations. Applied Soft Computing (ASOC), 2019, 80: 425-437. (JCR Q1/中科院一区Top期刊，Impact Factor: 7.2)</li>
  <li>[11]	T. Hou,<b>Q. Qi</b>, Y. Lu, K. Du, and H. Wang. Dual Selection Network for Video Object Detection. IEEE International Conference on Multimedia and Expo (ICME), 2022, DOI: 10.1109/ICME52920.2022.9859947. (CCF B 类会议，Oral)</li>
  <li>[12]	M. Jian, <b>Q. Qi</b>, J. Dong, et al. The OUC-Vision Large-Scale Underwater Image Database. IEEE International Conference on Multimedia and Expo (ICME), 2017: 1297-1302. (CCF B 类会议)</li>
  <li>[13]	Z. Qiu, <b>Q. Qi</b>, Y. Lu, Y. Yan, and H. Wang. Proposal Distillation of Multi-Modal Feature Aggregation Network for Video Object Detection. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2024. (CCF B类会议)</li>
  <li>[14]	M. Jian, <b>Q. Qi</b>, J. Dong, et al. Saliency Detection Using Quaternionic Distance Based Weber Local Descriptor and Level Priors. Multimedia tools and applications, 2018, 77: 14343-14360.</li>
  <li>[15]	M. Jian,<b>Q. Qi</b>, J. Dong, et al. Integrating QDWD With Pattern Distinctness and Local Contrast for Underwater Saliency Detection. Journal of Visual Communication and Image Representation, 2018, 53: 31-41.</li>
  <li>[16]	Z. Qiu,<b>Q. Qi</b>, Y. Yan, and H. Wang. DF-Net: Diversity-Focused Network for Video Object Detection. International Conference on Image Processing (ICIP), 2023, DOI: 10.1109/ICIP49359.2023.10223065. (CCF C 类会议)</li>
  <li>[17]	H. Ye,<b>Q. Qi</b>, Y. Wang, Y. Lu, and H. Wang. Global and Local Feature Alignment for Video Object Detection. ACM International Conference on Multimedia in Asia (MMAsia), 2021, DOI: 10.1145/3444685.3446263. (CCF C 类会议)</li>
  <li>[18]	M. Jian, <b>Q. Qi</b>, J. Dong, et al. Saliency Detection Using Quatemionic Distance Based Weber Descriptor and Object Cues. Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA). 2016: 1-4.</li>
  <li>[19]	X. Wang, F. Gao, J. Dong, and <b>Q. Qi</b>. Change Detection for Synthetic Aperture Radar Images Based on Pattern and Intensity Distinctiveness Analysis. International Conference on Graphic and Image Processing (ICGIP), 2018, 10615: 1209-1215. </li>
  </ul>
  <h2>专利</h2>
  <ul>
  <li><p>[1] 齐强, 尚文琦, 王晓. 基于时空图卷积的视频目标检测方法及系统. 国家发明专利，申请号：202411602105.4. </p>
  </li>
    <li>[2] 齐强, 尚文琦, 王晓. 基于交替解耦的视频目标检测方法及系统. 国家发明专利，申请号：202510101702.7.</li>
  </ul>
  <h2>参与项目</h2> 
  <ul>
  <li>[1]省部级，福厦泉国家自主创新示范区数据安全与视觉分析核心技
术研究协同创新平台项目（3502ZCQXT2022008），2023年1月-2024年12月，在研，技术骨干
</li> 
  <li>[2]之江实验室，面向复杂异构数据的联邦学习方法研究（2021KB0AB03），2021年1月-2022年12月，结题，技术骨干</li>
   <li>[3]厦门大学校长基金，面向非独立同分布长尾数据的联邦学习方法研究（20720210099），2021年1月-2022年12月，技术骨干</li> 
  </ul>
   <h2>课程</h2> 
  <ul>
  <li><p>本科生课程，JAVA语言程序设计</p> 
  </li>
  <li>本科生课程，计算机导论与人工智能</li>
  </ul> 
  <div id="footer">
  <div id="footer-text">
  <br>
  </div>
  </div>
  </div>
  </body>
</html>
